{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook pour créer différents Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, LinearAlgebra, Distributions, Random, ScikitLearn, GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitdataframe"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    splitdataframe(df::DataFrame, p::Real)\n",
    "\n",
    "Partitionne en un ensemble d'entraînement et un ensemble de validation un DataFrame.\n",
    "\n",
    "### Arguments\n",
    "- `df::DataFrame` : Un DataFrame\n",
    "- `p::Real` : La proportion (entre 0 et 1) de données dans l'ensemble d'entraînement.\n",
    "\n",
    "### Détails\n",
    "\n",
    "La fonction renvoie deux DataFrames, un pour l'ensemble d'entraînement et l'autre pour l'ensemble de validation.\n",
    "\n",
    "### Exemple\n",
    "\n",
    "\\```\n",
    " julia> splitdataframe(df, p.7)\n",
    "\\```\n",
    "\n",
    "\"\"\"\n",
    "function splitdataframe(df::DataFrame, p::Real)\n",
    "   @assert 0 <= p <= 1 \n",
    "    \n",
    "    n = size(df,1)\n",
    "    \n",
    "    ind = shuffle(1:n)\n",
    "    \n",
    "    threshold = Int64(round(n*p))\n",
    "    \n",
    "    indTrain = sort(ind[1:threshold])\n",
    "    \n",
    "    indTest = setdiff(1:n,indTrain)\n",
    "    \n",
    "    dfTrain = df[indTrain,:]\n",
    "    dfTest = df[indTest,:]\n",
    "    \n",
    "    return dfTrain, dfTest\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour compter le nombre de valeurs \"missing\" dans une ligne d'un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countMissing (generic function with 1 method)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function countMissing(line)\n",
    "    count=0\n",
    "    ind = 0\n",
    "    for i=1:length(line)\n",
    "        if (ismissing(line[i]))\n",
    "            count += 1\n",
    "            ind = i\n",
    "        end\n",
    "    end\n",
    "    return count, ind\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction permettant de calculer le moyenne des valeurs d'une ligne peu importe le nombre de \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanLine (generic function with 1 method)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function meanLine(line)\n",
    "    values = []\n",
    "    for i=1:length(line)\n",
    "        if (!ismissing(line[i]))\n",
    "            append!(values,line[i])\n",
    "        end\n",
    "    end\n",
    "    return mean(values)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'encodage OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oneHot (generic function with 1 method)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function oneHot(df_grouped)\n",
    "    oneHotMatrix = []\n",
    "    dateVector = []\n",
    "    oneHotDF = DataFrame()\n",
    "    for df in df_grouped\n",
    "        vector = zeros(5)\n",
    "        for row = eachrow(df)\n",
    "            i = findfirst(x -> x==row[:NO_OUVRAGE], OUVRAGES)\n",
    "            vector[i] = row[:SURVERSE]\n",
    "        end\n",
    "        push!(dateVector, df[:DATE][1])\n",
    "        push!(oneHotMatrix, vector)\n",
    "    end\n",
    "    oneHotDF.one_hot = oneHotMatrix\n",
    "    oneHotDF.date = dateVector\n",
    "    return oneHotDF\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction permettant de remplacer toutes les valeurs \"missing\" d'une ligne avec la valeur donnée en parametre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "replaceMissing (generic function with 1 method)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function replaceMissing(line,value)\n",
    "    n = length(line)\n",
    "    for i=1:n\n",
    "        if (ismissing(line[i]))\n",
    "            line[i] = value\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"./data/surverses.csv\", missingstring=\"-99999\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.DATE) > 4, data) \n",
    "data = filter(row -> month(row.DATE) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data[:,:RAISON],\"Inconnue\")\n",
    "data[!,:RAISON] = raison\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data) \n",
    "select!(data, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>date</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & date & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ date       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surverse_df = dropmissing(data, disallowmissing=true)\n",
    "rename!(surverse_df, :DATE=>:date)\n",
    "first(surverse_df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-01-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-01-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-01-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-01-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-01-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-01-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-01-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-01-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-01-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-01-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-01-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-01-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-01-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-01-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-01-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-05-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-05-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-05-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-05-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-05-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-05-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-05-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-05-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-05-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-05-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-05-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-05-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-05-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-05-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-05-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.date) > 4, data) \n",
    "data = filter(row -> month(row.date) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Remplissage des données manquantes\n",
    "Nous allons tenter de remplir les données manquantes par des moyennes de précipitations lorsque les données sont inconnues pour 2 stations ou plus afin d'avoir plus de données pour créer nos modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques pour remplir les données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utiliser regression ridge pour remplir les ligne ou il y a une valeur manquante \n",
    "- remplir les lignes avec plusieurs valeurs manquantes avec la moyenne des valeurs présentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction Ridge pour trouver les valueurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridge (generic function with 1 method)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction pour faire une regression ridge\n",
    "# Ressort le beta, m, et s\n",
    "function ridge(datas::DataFrame, station::Symbol)\n",
    "       \n",
    "    Train, Test = splitdataframe(datas, .75);\n",
    "    # Prétraitement des données\n",
    "    # Les variables avec les tildes correspondent à l'échantillon de test\n",
    "\n",
    "    X = convert(Matrix{Int64},Train[:,Not(station)])\n",
    "    m = mean(X, dims=1)\n",
    "    s = std(X, dims=1)\n",
    "    m[2] = 0\n",
    "    s[2] = 1\n",
    "    X = (X .- m) ./ s\n",
    "\n",
    "    X̃ = convert(Matrix{Int64},Test[:,Not(station)])\n",
    "    X̃ = (X̃ .- m) ./ s\n",
    "\n",
    "    y = convert(Vector{Int64}, Train[:,station])\n",
    "    m = mean(y)\n",
    "    s = std(y)\n",
    "    y = (y .- m) ./s\n",
    "\n",
    "    ỹ = convert(Vector{Int64}, Test[:,station])\n",
    "    ỹ = (ỹ .- m) ./s;\n",
    "\n",
    "    #On calcule ensuite le RMSE pour chacun des valeurs de lambda\n",
    "    RMSEs = DataFrame(λ=Float64[], RMSE=Float64[])\n",
    "\n",
    "    for λ in 0:1:10000\n",
    "   \n",
    "        β̂ = (X'X + λ*I)\\X'y\n",
    "    \n",
    "        ŷ = X̃*β̂\n",
    "    \n",
    "        ẽ = ỹ - ŷ\n",
    "    \n",
    "        RMSE = sqrt(dot(ẽ,ẽ)/length(ẽ))\n",
    "    \n",
    "        push!(RMSEs, [λ, RMSE])\n",
    "    \n",
    "    end\n",
    "    \n",
    "    # On trouve ensuite la valeure de lambda qui minimise le RMSE\n",
    "    _, ind = findmin(RMSEs[:,:RMSE])\n",
    "\n",
    "    λ̂ = RMSEs[ind,:λ]\n",
    "    \n",
    "    β̂ = (X'X + λ̂*I)\\X'y\n",
    "    \n",
    "    #TODO validate model and print value of validator R² ajuste\n",
    "    \n",
    "    #On peut alors calculer les y avec les betas trouver et l'echantillon de test\n",
    "    ŷ = X̃ * β̂\n",
    "    ŷ = round.((ŷ .* s) .+ m)\n",
    "    \n",
    "    # Calcul du R² ajusté\n",
    "\n",
    "    p = 4          # nombre de variables explicatives\n",
    "    n = length(ỹ)  # taille de l'échantillon\n",
    "\n",
    "    ỹ = (ỹ .* s) .+ m\n",
    "    ȳ = mean(ỹ)\n",
    "    e = ỹ - ŷ\n",
    "\n",
    "    SST = sum( (ỹ[i] - ȳ)^2 for i=1:n )  # variabilité totale\n",
    "    SSE = sum( e.^2 )                    # variabilité résiduelle\n",
    "\n",
    "    R2aj =  1 - SSE/SST * (n-1)/(n-p)\n",
    "    \n",
    "    println(\"Le R² ajuste du modele trouve pour la station de $(station) est $(R2aj)\")\n",
    "    \n",
    "    return β̂\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 5)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilisations des données connues pour bâtire les modèles de prédiction Ridge\n",
    "full_data = dropmissing(data, disallowmissing=true)\n",
    "full_data = full_data[:,Not(:date)][:, Not(:heure)]\n",
    "size(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des betas par station manquante (prédite)\n",
    "betas = DataFrame(station = Symbol[], β = Array{Float64}[])\n",
    "for name in names(full_data)\n",
    "    β̂ = ridge(full_data, name)\n",
    "    push!(betas, [name, β̂])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplissage des données en effectuant la moyenne des données présentes si plus de 1 est manquante, sinon utilisation du modèle Ridge approprié à la station manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precipitation_df = data[:,Not(:date)][:,Not(:heure)]\n",
    "for row in eachrow(precipitation_df)\n",
    "    nbMissing, ind = countMissing(row)\n",
    "    if(nbMissing == 1)\n",
    "        row[ind] = round((convert(Vector{Float64},row[Not(ind)])'*betas[:, :β][ind]))\n",
    "    end\n",
    "    # remplacer les lignes qui ont de 2 a 4 missing\n",
    "    if(nbMissing<5 && nbMissing>1)\n",
    "        replaceMissing(row,round(meanLine(row)))\n",
    "    end\n",
    "end\n",
    "precipitation_df.heure = data[:,:heure]\n",
    "precipitation_df.date = data[:,:date]\n",
    "precipitation_df = dropmissing(precipitation_df) # drop all missing\n",
    "CSV.write(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\",precipitation_df)\n",
    "first(precipitation_df,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : somme des précipitations par jour pour les stations de précipitations\n",
    "- Nous pensons que cela pourrait bien expliquer des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precipitation_daily_sum = by(precipitation_df, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum)\n",
    "last(precipitation_daily_sum ,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire l'année 2019 pour les données à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_daily_sum_train = filter(row -> Year(row[:date]) != Year(2019), precipitation_daily_sum)\n",
    "precipitation_daily_sum_pred  = filter(row -> Year(row[:date]) == Year(2019), precipitation_daily_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envoyer vers fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.date in surverse_df[!, :date], precipitation_daily_sum_train)\n",
    "filter!(row -> row.date in precipitation_daily_sum_train[!, :date], surverse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"data/new_datasets/precipitation_daily_sum/x_train.csv\", precipitation_daily_sum_train)\n",
    "CSV.write(\"data/new_datasets/precipitation_daily_sum/x_pred.csv\", precipitation_daily_sum_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : Maximum des précipitations par jour pour les stations de précipitations\n",
    "- Nous pensons que cela pourrait bien expliquer des surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction du taux horaire journalier maximum des précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precipitation_daily_max = by(precipitation_df, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(precipitation_daily_max,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire l'année 2019 pour les données à prédire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precipitation_daily_max_train = filter(row -> Year(row[:date]) != Year(2019), precipitation_daily_max)\n",
    "precipitation_daily_max_pred  = filter(row -> Year(row[:date]) == Year(2019), precipitation_daily_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envoyer vers fichier CSV\n",
    "Valider que les dates correspondent pour x et y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter!(row -> row.date in surverse_df[!, :date], precipitation_daily_max_train)\n",
    "filter!(row -> row.date in precipitation_daily_max_train[!, :date], surverse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"./data/new_datasets/precipitation_daily_max/x_train.csv\", precipitation_daily_max_train)\n",
    "CSV.write(\"./data/new_datasets/precipitation_daily_max/x_pred.csv\", precipitation_daily_max_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"./data/new_datasets/surverse_list.csv\", surverse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : somme plus importante de précipitations par plages horaires sur une journée \n",
    "- Nous avons extrait cette varibale explicative avec l'idéé en tête que quelsques heures consécutives avec beaucoup de précipitations pourraient causer des surverses plus que des précipitations modérées réparties sur une journée complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filledPrec  = CSV.read(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\", missingstring=\"-99999\")\n",
    "first(filledPrec,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions pour séparer les journées en plages horaires de taille \"window\" et effectuer la somme des précipiations sur chaque plage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function dayPrecipitationSplit(window,precipitations)\n",
    "    n = size(precipitations,1)\n",
    "    newDf = DataFrame(McTavish = Int64[], Bellevue = Int64[], Assomption = Int64[], Trudeau  = Int64[],\n",
    "                        StHubert = Int64[], heureDebut = Int64[], heureFin = Int64[], date = Date[])\n",
    "\n",
    "    hourgroups = 24/window\n",
    "    for day in groupby(filledPrec, :date)\n",
    "        start = 1\n",
    "        finish = window\n",
    "        date = day[1,:date]\n",
    "        if(size(day, 1)==24)\n",
    "            for i=1:hourgroups\n",
    "                mcTavish, Bellevue, Assomption, Trudeau, StHubert, heureDebut, heureFin = 0,0,0,0,0,0,0\n",
    "                for j=start:finish\n",
    "                    mcTavish += day[j,:McTavish]\n",
    "                    Assomption += day[j,:Assomption]\n",
    "                    Bellevue += day[j,:Bellevue]\n",
    "                    Trudeau += day[j,:Trudeau]\n",
    "                    StHubert += day[j,:StHubert]\n",
    "                    if j == start\n",
    "                        heureDebut = day[j,:heure]\n",
    "                    elseif j == finish\n",
    "                        heureFin = day[j,:heure]\n",
    "                    end\n",
    "                end\n",
    "                start += window\n",
    "                finish += window\n",
    "                push!(newDf,[mcTavish,Bellevue,Assomption,Trudeau,StHubert,heureDebut,heureFin,date])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return newDf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Générations des sommes de plages horaires pour des divisions de journées de 2,3,4,6,8 et 12 heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourSplit2 = dayPrecipitationSplit(2,filledPrec)\n",
    "hourSplit3 = dayPrecipitationSplit(3,filledPrec)\n",
    "hourSplit4 = dayPrecipitationSplit(4,filledPrec)\n",
    "hourSplit6 = dayPrecipitationSplit(6,filledPrec)\n",
    "hourSplit8 = dayPrecipitationSplit(8,filledPrec)\n",
    "hourSplit12 = dayPrecipitationSplit(12,filledPrec)\n",
    "first(hourSplit12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour extraire la plage horaire avec la somme des précipitations la plus grande pour chaque jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxPrecByDay(Prec)\n",
    "    n = size(Prec,1)\n",
    "    newDf = DataFrame(McTavish = Int64[], Bellevue = Int64[], Assomption = Int64[], Trudeau  = Int64[],\n",
    "                        StHubert = Int64[], date = Date[])\n",
    "\n",
    "    for day in groupby(Prec, :date)\n",
    "        mcTavish = maximum(day[:,:McTavish])\n",
    "        Assomption = maximum(day[:,:Assomption])\n",
    "        Bellevue = maximum(day[:,:Bellevue])\n",
    "        Trudeau = maximum(day[:,:Trudeau])\n",
    "        StHubert = maximum(day[:,:StHubert])\n",
    "        date = day[1,:date]\n",
    "        push!(newDf,[mcTavish,Bellevue,Assomption,Trudeau,StHubert,date])\n",
    "    end\n",
    "    return newDf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets contenant la nouvelle variables explicative pour les 5 stations pour les journées divisée par sections de 2,3,4,6,8 et 12 heures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSum2hours = maxPrecByDay(hourSplit2)\n",
    "maxSum3hours = maxPrecByDay(hourSplit3)\n",
    "maxSum4hours = maxPrecByDay(hourSplit4)\n",
    "maxSum6hours = maxPrecByDay(hourSplit6)\n",
    "maxSum8hours = maxPrecByDay(hourSplit8)\n",
    "maxSum12hours = maxPrecByDay(hourSplit12)\n",
    "first(maxSum12hours,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Écriture des dataframes ver des fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy2hours.csv\",maxSum2hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy3hours.csv\",maxSum3hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy4hours.csv\",maxSum4hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy6hours.csv\",maxSum6hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy8hours.csv\",maxSum8hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy12hours.csv\",maxSum12hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : Somme de la journee + les deux dernieres heures du jour précédent\n",
    "- Nous avons décidé d'ajouter les deux heures de la journée précedente, car nous croyons que les dernières heures de cette journée peuvent effet impoartant sur la journée qui suit et pas sur celle dont elles font parite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filledPrec  = CSV.read(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\", missingstring=\"-99999\")\n",
    "first(filledPrec,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Somme et ajout des 2 dernières heures de la journée précédente pour les précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(precipitation_daily_sum, 1)\n",
    "    ind = findfirst(filledPrec[:,:date] .== precipitation_daily_sum[i,:date])\n",
    "    for h=1:2\n",
    "        for key in names(precipitation_daily_sum[:, Not(:date)])\n",
    "            if ind-h > 0\n",
    "                precipitation_daily_sum[i, key] += filledPrec[ind-h, key]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "first(precipitation_daily_sum, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportation vers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"./data/new_datasets/sum_day_last_2.csv\",precipitation_daily_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset avec toutes les surverses des autres ouvrages ayant assez de données par date\n",
    "- Nous n'avons finalement pas utilisé ces données, car il y avait une quatité très importante de données manquantes et nous n'avions pas accès aux données pour 2019 afin d'effectuer les préditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surversesVoisines = DataFrame()\n",
    "surversesVoisines[:,:date] = maxSum2hours[:,:date]\n",
    "ouvrages = groupby(surverse_df, :NO_OUVRAGE)\n",
    "for subdf in ouvrages\n",
    "            length = (size(subdf, 1))\n",
    "            if (length > 1000)\n",
    "                subdf = rename(subdf,:SURVERSE => subdf[1,:NO_OUVRAGE])\n",
    "                dateAndSurverse = subdf[:,Not(:NO_OUVRAGE)]\n",
    "                surversesVoisines = join(surversesVoisines, dateAndSurverse, on = :date, kind = :left)    \n",
    "            end\n",
    "       end\n",
    "first(surversesVoisines,5)\n",
    "CSV.write(\"./data/new_datasets/surversesVoisines\",surversesVoisines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
