{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook To create all sorts of DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all new datasets in `data/new datasets/`\n",
    "\n",
    "All datasets should have their own subFolder with files \n",
    "\n",
    "`x_train` columns: All variable names with index 0-XXX in numbers (no arrays)\n",
    "\n",
    "`y_train` column: y column of 0/1 boolean values\n",
    "\n",
    "`x_pred` same as x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, LinearAlgebra, Distributions, Random, ScikitLearn, GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitdataframe"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    splitdataframe(df::DataFrame, p::Real)\n",
    "\n",
    "Partitionne en un ensemble d'entraînement et un ensemble de validation un DataFrame.\n",
    "\n",
    "### Arguments\n",
    "- `df::DataFrame` : Un DataFrame\n",
    "- `p::Real` : La proportion (entre 0 et 1) de données dans l'ensemble d'entraînement.\n",
    "\n",
    "### Détails\n",
    "\n",
    "La fonction renvoie deux DataFrames, un pour l'ensemble d'entraînement et l'autre pour l'ensemble de validation.\n",
    "\n",
    "### Exemple\n",
    "\n",
    "\\```\n",
    " julia> splitdataframe(df, p.7)\n",
    "\\```\n",
    "\n",
    "\"\"\"\n",
    "function splitdataframe(df::DataFrame, p::Real)\n",
    "   @assert 0 <= p <= 1 \n",
    "    \n",
    "    n = size(df,1)\n",
    "    \n",
    "    ind = shuffle(1:n)\n",
    "    \n",
    "    threshold = Int64(round(n*p))\n",
    "    \n",
    "    indTrain = sort(ind[1:threshold])\n",
    "    \n",
    "    indTest = setdiff(1:n,indTrain)\n",
    "    \n",
    "    dfTrain = df[indTrain,:]\n",
    "    dfTest = df[indTest,:]\n",
    "    \n",
    "    return dfTrain, dfTest\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"./data/surverses.csv\", missingstring=\"-99999\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.DATE) > 4, data) \n",
    "data = filter(row -> month(row.DATE) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data[:,:RAISON],\"Inconnue\")\n",
    "data[!,:RAISON] = raison\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data) \n",
    "select!(data, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>date</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & date & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ date       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surverse_df = dropmissing(data, disallowmissing=true)\n",
    "rename!(surverse_df, :DATE=>:date)\n",
    "first(surverse_df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-01-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-01-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-01-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-01-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-01-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-01-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-01-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-01-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-01-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-01-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-01-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-01-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-01-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-01-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-01-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2013-05-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>2013-05-01</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>2013-05-01</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2013-05-01</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>2013-05-01</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-05-01 & 0 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t2 & 2013-05-01 & 1 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t3 & 2013-05-01 & 2 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2013-05-01 & 3 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t5 & 2013-05-01 & 4 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-05-01 │ 0     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2013-05-01 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-05-01 │ 2     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2013-05-01 │ 3     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2013-05-01 │ 4     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(row -> month(row.date) > 4, data) \n",
    "data = filter(row -> month(row.date) < 11, data) \n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Remplissage des données manquantes\n",
    "Nous allons tenter de remplir les données manquantes par des moyennes de précipitations lorsque les données sont inconnues pour 2 stations ou plus afin d'avoir plus de données pour créer nos modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques pour remplir les données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utiliser regression ridge pour remplir les ligne ou il y a une valeur manquante \n",
    "- remplir les lignes avec plusieurs valeurs manquantes avec la moyenne des valeurs présentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction Ridge pour trouver les valueurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridge (generic function with 1 method)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction pour faire une regression ridge\n",
    "# Ressort le beta, m, et s\n",
    "function ridge(datas::DataFrame, station::Symbol)\n",
    "       \n",
    "    Train, Test = splitdataframe(datas, .75);\n",
    "    # Prétraitement des données\n",
    "    # Les variables avec les tildes correspondent à l'échantillon de test\n",
    "\n",
    "    X = convert(Matrix{Int64},Train[:,Not(station)])\n",
    "    m = mean(X, dims=1)\n",
    "    s = std(X, dims=1)\n",
    "    m[2] = 0\n",
    "    s[2] = 1\n",
    "    X = (X .- m) ./ s\n",
    "\n",
    "    X̃ = convert(Matrix{Int64},Test[:,Not(station)])\n",
    "    X̃ = (X̃ .- m) ./ s\n",
    "\n",
    "    y = convert(Vector{Int64}, Train[:,station])\n",
    "    m = mean(y)\n",
    "    s = std(y)\n",
    "    y = (y .- m) ./s\n",
    "\n",
    "    ỹ = convert(Vector{Int64}, Test[:,station])\n",
    "    ỹ = (ỹ .- m) ./s;\n",
    "\n",
    "    #On calcule ensuite le RMSE pour chacun des valeurs de lambda\n",
    "    RMSEs = DataFrame(λ=Float64[], RMSE=Float64[])\n",
    "\n",
    "    for λ in 0:1:10000\n",
    "   \n",
    "        β̂ = (X'X + λ*I)\\X'y\n",
    "    \n",
    "        ŷ = X̃*β̂\n",
    "    \n",
    "        ẽ = ỹ - ŷ\n",
    "    \n",
    "        RMSE = sqrt(dot(ẽ,ẽ)/length(ẽ))\n",
    "    \n",
    "        push!(RMSEs, [λ, RMSE])\n",
    "    \n",
    "    end\n",
    "    \n",
    "    # On trouve ensuite la valeure de lambda qui minimise le RMSE\n",
    "    _, ind = findmin(RMSEs[:,:RMSE])\n",
    "\n",
    "    λ̂ = RMSEs[ind,:λ]\n",
    "    \n",
    "    β̂ = (X'X + λ̂*I)\\X'y\n",
    "    \n",
    "    #TODO validate model and print value of validator R² ajuste\n",
    "    \n",
    "    #On peut alors calculer les y avec les betas trouver et l'echantillon de test\n",
    "    ŷ = X̃ * β̂\n",
    "    ŷ = round.((ŷ .* s) .+ m)\n",
    "    \n",
    "    # Calcul du R² ajusté\n",
    "\n",
    "    p = 4          # nombre de variables explicatives\n",
    "    n = length(ỹ)  # taille de l'échantillon\n",
    "\n",
    "    ỹ = (ỹ .* s) .+ m\n",
    "    ȳ = mean(ỹ)\n",
    "    e = ỹ - ŷ\n",
    "\n",
    "    SST = sum( (ỹ[i] - ȳ)^2 for i=1:n )  # variabilité totale\n",
    "    SSE = sum( e.^2 )                    # variabilité résiduelle\n",
    "\n",
    "    R2aj =  1 - SSE/SST * (n-1)/(n-p)\n",
    "    \n",
    "    println(\"Le R² ajuste du modele trouve pour la station de $(station) est $(R2aj)\")\n",
    "    \n",
    "    return β̂\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 5)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilisations des données connues pour bâtire les modèles de prédiction Ridge\n",
    "full_data = dropmissing(data, disallowmissing=true)\n",
    "full_data = full_data[:,Not(:date)][:, Not(:heure)]\n",
    "size(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le R² ajuste du modele trouve pour la station de McTavish est 0.6818964239458101\n",
      "Le R² ajuste du modele trouve pour la station de Bellevue est 0.44965617430197047\n",
      "Le R² ajuste du modele trouve pour la station de Assomption est 0.2259669596460928\n",
      "Le R² ajuste du modele trouve pour la station de Trudeau est 0.6124946856258109\n",
      "Le R² ajuste du modele trouve pour la station de StHubert est 0.4706529979050087\n"
     ]
    }
   ],
   "source": [
    "# Liste des betas par station manquante (prédite)\n",
    "betas = DataFrame(station = Symbol[], β = Array{Float64}[])\n",
    "for name in names(full_data)\n",
    "    β̂ = ridge(full_data, name)\n",
    "    push!(betas, [name, β̂])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplissage des données en effectuant la moyenne des données présentes si plus de 1 est manquante, sinon utilisation du modèle Ridge approprié à la station manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th><th>heure</th><th>date</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Date</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-01</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2013-05-01</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2013-05-01</td></tr><tr><th>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2013-05-01</td></tr><tr><th>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>2013-05-01</td></tr><tr><th>6</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>2013-05-01</td></tr><tr><th>7</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>6</td><td>2013-05-01</td></tr><tr><th>8</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>7</td><td>2013-05-01</td></tr><tr><th>9</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>8</td><td>2013-05-01</td></tr><tr><th>10</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>9</td><td>2013-05-01</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& McTavish & Bellevue & Assomption & Trudeau & StHubert & heure & date\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 0 & 2013-05-01 \\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 1 & 2013-05-01 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 2 & 2013-05-01 \\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 3 & 2013-05-01 \\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 4 & 2013-05-01 \\\\\n",
       "\t6 & 0 & 0 & 0 & 0 & 0 & 5 & 2013-05-01 \\\\\n",
       "\t7 & 0 & 0 & 0 & 0 & 0 & 6 & 2013-05-01 \\\\\n",
       "\t8 & 0 & 0 & 0 & 0 & 0 & 7 & 2013-05-01 \\\\\n",
       "\t9 & 0 & 0 & 0 & 0 & 0 & 8 & 2013-05-01 \\\\\n",
       "\t10 & 0 & 0 & 0 & 0 & 0 & 9 & 2013-05-01 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │ heure │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼──────────┼──────────┼────────────┼─────────┼──────────┼───────┤\n",
       "│ 1   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0     │\n",
       "│ 2   │ 0        │ 0        │ 0          │ 0       │ 0        │ 1     │\n",
       "│ 3   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2     │\n",
       "│ 4   │ 0        │ 0        │ 0          │ 0       │ 0        │ 3     │\n",
       "│ 5   │ 0        │ 0        │ 0          │ 0       │ 0        │ 4     │\n",
       "│ 6   │ 0        │ 0        │ 0          │ 0       │ 0        │ 5     │\n",
       "│ 7   │ 0        │ 0        │ 0          │ 0       │ 0        │ 6     │\n",
       "│ 8   │ 0        │ 0        │ 0          │ 0       │ 0        │ 7     │\n",
       "│ 9   │ 0        │ 0        │ 0          │ 0       │ 0        │ 8     │\n",
       "│ 10  │ 0        │ 0        │ 0          │ 0       │ 0        │ 9     │"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"datasets/countMissing.jl\")\n",
    "include(\"datasets/meanLine.jl\")\n",
    "include(\"datasets/replaceMissing.jl\")\n",
    "precipitation_df = data[:,Not(:date)][:,Not(:heure)]\n",
    "for row in eachrow(precipitation_df)\n",
    "    nbMissing, ind = countMissing(row)\n",
    "    if(nbMissing == 1)\n",
    "        row[ind] = round((convert(Vector{Float64},row[Not(ind)])'*betas[:, :β][ind]))\n",
    "    end\n",
    "    # remplacer les lignes qui ont de 2 a 4 missing\n",
    "    if(nbMissing<5 && nbMissing>1)\n",
    "        replaceMissing(row,round(meanLine(row)))\n",
    "    end\n",
    "end\n",
    "precipitation_df.heure = data[:,:heure]\n",
    "precipitation_df.date = data[:,:date]\n",
    "precipitation_df = dropmissing(precipitation_df) # drop all missing\n",
    "CSV.write(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\",precipitation_df)\n",
    "first(precipitation_df,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : somme des précipitations par jour pour les stations de précipitations\n",
    "- Nous pensons que cela pourrait bien expliquer des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-10-21</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2019-10-22</td><td>104</td><td>109</td><td>109</td><td>129</td><td>92</td></tr><tr><th>3</th><td>2019-10-23</td><td>152</td><td>138</td><td>138</td><td>114</td><td>149</td></tr><tr><th>4</th><td>2019-10-24</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2019-10-25</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>2019-10-26</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>2019-10-27</td><td>442</td><td>378</td><td>378</td><td>352</td><td>341</td></tr><tr><th>8</th><td>2019-10-28</td><td>7</td><td>6</td><td>6</td><td>2</td><td>6</td></tr><tr><th>9</th><td>2019-10-29</td><td>0</td><td>1</td><td>1</td><td>0</td><td>2</td></tr><tr><th>10</th><td>2019-10-30</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-10-21 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2019-10-22 & 104 & 109 & 109 & 129 & 92 \\\\\n",
       "\t3 & 2019-10-23 & 152 & 138 & 138 & 114 & 149 \\\\\n",
       "\t4 & 2019-10-24 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2019-10-25 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 2019-10-26 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 2019-10-27 & 442 & 378 & 378 & 352 & 341 \\\\\n",
       "\t8 & 2019-10-28 & 7 & 6 & 6 & 2 & 6 \\\\\n",
       "\t9 & 2019-10-29 & 0 & 1 & 1 & 0 & 2 \\\\\n",
       "\t10 & 2019-10-30 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-10-21 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 2   │ 2019-10-22 │ 104      │ 109      │ 109        │ 129     │ 92       │\n",
       "│ 3   │ 2019-10-23 │ 152      │ 138      │ 138        │ 114     │ 149      │\n",
       "│ 4   │ 2019-10-24 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 5   │ 2019-10-25 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 6   │ 2019-10-26 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 7   │ 2019-10-27 │ 442      │ 378      │ 378        │ 352     │ 341      │\n",
       "│ 8   │ 2019-10-28 │ 7        │ 6        │ 6          │ 2       │ 6        │\n",
       "│ 9   │ 2019-10-29 │ 0        │ 1        │ 1          │ 0       │ 2        │\n",
       "│ 10  │ 2019-10-30 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation_daily_sum = by(precipitation_df, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum)\n",
    "last(precipitation_daily_sum ,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire l'année 2019 pour les données à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>183 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>79</td><td>52</td><td>58</td><td>47</td><td>68</td></tr><tr><th>2</th><td>2019-05-02</td><td>26</td><td>19</td><td>15</td><td>13</td><td>17</td></tr><tr><th>3</th><td>2019-05-03</td><td>34</td><td>27</td><td>34</td><td>31</td><td>44</td></tr><tr><th>4</th><td>2019-05-04</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>2019-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>2019-05-06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>2019-05-07</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>8</th><td>2019-05-08</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>2019-05-09</td><td>89</td><td>67</td><td>77</td><td>86</td><td>67</td></tr><tr><th>10</th><td>2019-05-10</td><td>385</td><td>265</td><td>286</td><td>285</td><td>316</td></tr><tr><th>11</th><td>2019-05-11</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>12</th><td>2019-05-12</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>13</th><td>2019-05-13</td><td>18</td><td>22</td><td>0</td><td>9</td><td>5</td></tr><tr><th>14</th><td>2019-05-14</td><td>95</td><td>130</td><td>62</td><td>104</td><td>84</td></tr><tr><th>15</th><td>2019-05-15</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>16</th><td>2019-05-16</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>17</th><td>2019-05-17</td><td>5</td><td>11</td><td>0</td><td>3</td><td>5</td></tr><tr><th>18</th><td>2019-05-18</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>19</th><td>2019-05-19</td><td>65</td><td>56</td><td>37</td><td>57</td><td>62</td></tr><tr><th>20</th><td>2019-05-20</td><td>46</td><td>5</td><td>49</td><td>53</td><td>50</td></tr><tr><th>21</th><td>2019-05-21</td><td>0</td><td>0</td><td>3</td><td>2</td><td>0</td></tr><tr><th>22</th><td>2019-05-22</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>23</th><td>2019-05-23</td><td>175</td><td>118</td><td>351</td><td>159</td><td>213</td></tr><tr><th>24</th><td>2019-05-24</td><td>13</td><td>10</td><td>22</td><td>15</td><td>14</td></tr><tr><th>25</th><td>2019-05-25</td><td>0</td><td>2</td><td>7</td><td>4</td><td>6</td></tr><tr><th>26</th><td>2019-05-26</td><td>3</td><td>4</td><td>21</td><td>5</td><td>7</td></tr><tr><th>27</th><td>2019-05-27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>28</th><td>2019-05-28</td><td>3</td><td>8</td><td>0</td><td>15</td><td>10</td></tr><tr><th>29</th><td>2019-05-29</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td></tr><tr><th>30</th><td>2019-05-30</td><td>7</td><td>7</td><td>13</td><td>12</td><td>10</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 79 & 52 & 58 & 47 & 68 \\\\\n",
       "\t2 & 2019-05-02 & 26 & 19 & 15 & 13 & 17 \\\\\n",
       "\t3 & 2019-05-03 & 34 & 27 & 34 & 31 & 44 \\\\\n",
       "\t4 & 2019-05-04 & 2 & 0 & 0 & 2 & 0 \\\\\n",
       "\t5 & 2019-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 2019-05-06 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 2019-05-07 & 3 & 0 & 0 & 0 & 0 \\\\\n",
       "\t8 & 2019-05-08 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t9 & 2019-05-09 & 89 & 67 & 77 & 86 & 67 \\\\\n",
       "\t10 & 2019-05-10 & 385 & 265 & 286 & 285 & 316 \\\\\n",
       "\t11 & 2019-05-11 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t12 & 2019-05-12 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t13 & 2019-05-13 & 18 & 22 & 0 & 9 & 5 \\\\\n",
       "\t14 & 2019-05-14 & 95 & 130 & 62 & 104 & 84 \\\\\n",
       "\t15 & 2019-05-15 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t16 & 2019-05-16 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t17 & 2019-05-17 & 5 & 11 & 0 & 3 & 5 \\\\\n",
       "\t18 & 2019-05-18 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t19 & 2019-05-19 & 65 & 56 & 37 & 57 & 62 \\\\\n",
       "\t20 & 2019-05-20 & 46 & 5 & 49 & 53 & 50 \\\\\n",
       "\t21 & 2019-05-21 & 0 & 0 & 3 & 2 & 0 \\\\\n",
       "\t22 & 2019-05-22 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t23 & 2019-05-23 & 175 & 118 & 351 & 159 & 213 \\\\\n",
       "\t24 & 2019-05-24 & 13 & 10 & 22 & 15 & 14 \\\\\n",
       "\t25 & 2019-05-25 & 0 & 2 & 7 & 4 & 6 \\\\\n",
       "\t26 & 2019-05-26 & 3 & 4 & 21 & 5 & 7 \\\\\n",
       "\t27 & 2019-05-27 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t28 & 2019-05-28 & 3 & 8 & 0 & 15 & 10 \\\\\n",
       "\t29 & 2019-05-29 & 0 & 1 & 0 & 2 & 0 \\\\\n",
       "\t30 & 2019-05-30 & 7 & 7 & 13 & 12 & 10 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "183×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-05-01 │ 79       │ 52       │ 58         │ 47      │ 68       │\n",
       "│ 2   │ 2019-05-02 │ 26       │ 19       │ 15         │ 13      │ 17       │\n",
       "│ 3   │ 2019-05-03 │ 34       │ 27       │ 34         │ 31      │ 44       │\n",
       "│ 4   │ 2019-05-04 │ 2        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 5   │ 2019-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 6   │ 2019-05-06 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 7   │ 2019-05-07 │ 3        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 8   │ 2019-05-08 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 9   │ 2019-05-09 │ 89       │ 67       │ 77         │ 86      │ 67       │\n",
       "│ 10  │ 2019-05-10 │ 385      │ 265      │ 286        │ 285     │ 316      │\n",
       "⋮\n",
       "│ 173 │ 2019-10-20 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 174 │ 2019-10-21 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 175 │ 2019-10-22 │ 104      │ 109      │ 109        │ 129     │ 92       │\n",
       "│ 176 │ 2019-10-23 │ 152      │ 138      │ 138        │ 114     │ 149      │\n",
       "│ 177 │ 2019-10-24 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 178 │ 2019-10-25 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 179 │ 2019-10-26 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 180 │ 2019-10-27 │ 442      │ 378      │ 378        │ 352     │ 341      │\n",
       "│ 181 │ 2019-10-28 │ 7        │ 6        │ 6          │ 2       │ 6        │\n",
       "│ 182 │ 2019-10-29 │ 0        │ 1        │ 1          │ 0       │ 2        │\n",
       "│ 183 │ 2019-10-30 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation_daily_sum_train = filter(row -> Year(row[:date]) != Year(2019), precipitation_daily_sum)\n",
    "precipitation_daily_sum_pred  = filter(row -> Year(row[:date]) == Year(2019), precipitation_daily_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envoyer vers fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>date</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>161,098 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr><tr><th>6</th><td>0642-01D</td><td>2013-05-06</td><td>0</td></tr><tr><th>7</th><td>0642-01D</td><td>2013-05-07</td><td>0</td></tr><tr><th>8</th><td>0642-01D</td><td>2013-05-08</td><td>0</td></tr><tr><th>9</th><td>0642-01D</td><td>2013-05-09</td><td>0</td></tr><tr><th>10</th><td>0642-01D</td><td>2013-05-10</td><td>0</td></tr><tr><th>11</th><td>0642-01D</td><td>2013-05-11</td><td>0</td></tr><tr><th>12</th><td>0642-01D</td><td>2013-05-12</td><td>0</td></tr><tr><th>13</th><td>0642-01D</td><td>2013-05-13</td><td>0</td></tr><tr><th>14</th><td>0642-01D</td><td>2013-05-14</td><td>0</td></tr><tr><th>15</th><td>0642-01D</td><td>2013-05-15</td><td>0</td></tr><tr><th>16</th><td>0642-01D</td><td>2013-05-16</td><td>0</td></tr><tr><th>17</th><td>0642-01D</td><td>2013-05-17</td><td>0</td></tr><tr><th>18</th><td>0642-01D</td><td>2013-05-18</td><td>0</td></tr><tr><th>19</th><td>0642-01D</td><td>2013-05-19</td><td>0</td></tr><tr><th>20</th><td>0642-01D</td><td>2013-05-20</td><td>0</td></tr><tr><th>21</th><td>0642-01D</td><td>2013-05-21</td><td>0</td></tr><tr><th>22</th><td>0642-01D</td><td>2013-05-22</td><td>0</td></tr><tr><th>23</th><td>0642-01D</td><td>2013-05-23</td><td>0</td></tr><tr><th>24</th><td>0642-01D</td><td>2013-05-24</td><td>0</td></tr><tr><th>25</th><td>0642-01D</td><td>2013-05-25</td><td>0</td></tr><tr><th>26</th><td>0642-01D</td><td>2013-05-26</td><td>0</td></tr><tr><th>27</th><td>0642-01D</td><td>2013-05-27</td><td>0</td></tr><tr><th>28</th><td>0642-01D</td><td>2013-05-28</td><td>0</td></tr><tr><th>29</th><td>0642-01D</td><td>2013-05-29</td><td>0</td></tr><tr><th>30</th><td>0642-01D</td><td>2013-05-30</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & date & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\t6 & 0642-01D & 2013-05-06 & 0 \\\\\n",
       "\t7 & 0642-01D & 2013-05-07 & 0 \\\\\n",
       "\t8 & 0642-01D & 2013-05-08 & 0 \\\\\n",
       "\t9 & 0642-01D & 2013-05-09 & 0 \\\\\n",
       "\t10 & 0642-01D & 2013-05-10 & 0 \\\\\n",
       "\t11 & 0642-01D & 2013-05-11 & 0 \\\\\n",
       "\t12 & 0642-01D & 2013-05-12 & 0 \\\\\n",
       "\t13 & 0642-01D & 2013-05-13 & 0 \\\\\n",
       "\t14 & 0642-01D & 2013-05-14 & 0 \\\\\n",
       "\t15 & 0642-01D & 2013-05-15 & 0 \\\\\n",
       "\t16 & 0642-01D & 2013-05-16 & 0 \\\\\n",
       "\t17 & 0642-01D & 2013-05-17 & 0 \\\\\n",
       "\t18 & 0642-01D & 2013-05-18 & 0 \\\\\n",
       "\t19 & 0642-01D & 2013-05-19 & 0 \\\\\n",
       "\t20 & 0642-01D & 2013-05-20 & 0 \\\\\n",
       "\t21 & 0642-01D & 2013-05-21 & 0 \\\\\n",
       "\t22 & 0642-01D & 2013-05-22 & 0 \\\\\n",
       "\t23 & 0642-01D & 2013-05-23 & 0 \\\\\n",
       "\t24 & 0642-01D & 2013-05-24 & 0 \\\\\n",
       "\t25 & 0642-01D & 2013-05-25 & 0 \\\\\n",
       "\t26 & 0642-01D & 2013-05-26 & 0 \\\\\n",
       "\t27 & 0642-01D & 2013-05-27 & 0 \\\\\n",
       "\t28 & 0642-01D & 2013-05-28 & 0 \\\\\n",
       "\t29 & 0642-01D & 2013-05-29 & 0 \\\\\n",
       "\t30 & 0642-01D & 2013-05-30 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "161098×3 DataFrame\n",
       "│ Row    │ NO_OUVRAGE │ date       │ SURVERSE │\n",
       "│        │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├────────┼────────────┼────────────┼──────────┤\n",
       "│ 1      │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2      │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3      │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4      │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5      │ 0642-01D   │ 2013-05-05 │ 0        │\n",
       "│ 6      │ 0642-01D   │ 2013-05-06 │ 0        │\n",
       "│ 7      │ 0642-01D   │ 2013-05-07 │ 0        │\n",
       "│ 8      │ 0642-01D   │ 2013-05-08 │ 0        │\n",
       "│ 9      │ 0642-01D   │ 2013-05-09 │ 0        │\n",
       "│ 10     │ 0642-01D   │ 2013-05-10 │ 0        │\n",
       "⋮\n",
       "│ 161088 │ 4795-01D   │ 2018-10-21 │ 0        │\n",
       "│ 161089 │ 4795-01D   │ 2018-10-22 │ 0        │\n",
       "│ 161090 │ 4795-01D   │ 2018-10-23 │ 0        │\n",
       "│ 161091 │ 4795-01D   │ 2018-10-24 │ 0        │\n",
       "│ 161092 │ 4795-01D   │ 2018-10-25 │ 0        │\n",
       "│ 161093 │ 4795-01D   │ 2018-10-26 │ 0        │\n",
       "│ 161094 │ 4795-01D   │ 2018-10-27 │ 0        │\n",
       "│ 161095 │ 4795-01D   │ 2018-10-28 │ 0        │\n",
       "│ 161096 │ 4795-01D   │ 2018-10-29 │ 0        │\n",
       "│ 161097 │ 4795-01D   │ 2018-10-30 │ 0        │\n",
       "│ 161098 │ 4795-01D   │ 2018-10-31 │ 0        │"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter!(row -> row.date in surverse_df[!, :date], precipitation_daily_sum_train)\n",
    "filter!(row -> row.date in precipitation_daily_sum_train[!, :date], surverse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/new_datasets/precipitation_daily_sum/x_pred.csv\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"data/new_datasets/precipitation_daily_sum/x_train.csv\", precipitation_daily_sum_train)\n",
    "CSV.write(\"data/new_datasets/precipitation_daily_sum/x_pred.csv\", precipitation_daily_sum_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : Maximum des précipitations par jour pour les stations de précipitations\n",
    "- Nous pensons que cela pourrait bien expliquer des surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction du taux horaire journalier maximum des précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2013-05-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2013-05-02</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2013-05-03</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>2013-05-04</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2013-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>2013-05-06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>2013-05-07</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>8</th><td>2013-05-08</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>2013-05-09</td><td>10</td><td>0</td><td>19</td><td>0</td><td>7</td></tr><tr><th>10</th><td>2013-05-10</td><td>0</td><td>4</td><td>20</td><td>0</td><td>2</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-05-01 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2013-05-02 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2013-05-03 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t4 & 2013-05-04 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2013-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 2013-05-06 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 2013-05-07 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t8 & 2013-05-08 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t9 & 2013-05-09 & 10 & 0 & 19 & 0 & 7 \\\\\n",
       "\t10 & 2013-05-10 & 0 & 4 & 20 & 0 & 2 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2013-05-01 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 2   │ 2013-05-02 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 3   │ 2013-05-03 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 4   │ 2013-05-04 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 5   │ 2013-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 6   │ 2013-05-06 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 7   │ 2013-05-07 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 8   │ 2013-05-08 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 9   │ 2013-05-09 │ 10       │ 0        │ 19         │ 0       │ 7        │\n",
       "│ 10  │ 2013-05-10 │ 0        │ 4        │ 20         │ 0       │ 2        │"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation_daily_max = by(precipitation_df, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(precipitation_daily_max,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire l'année 2019 pour les données à prédire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>183 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>24</td><td>24</td><td>15</td><td>21</td><td>22</td></tr><tr><th>2</th><td>2019-05-02</td><td>12</td><td>7</td><td>7</td><td>8</td><td>10</td></tr><tr><th>3</th><td>2019-05-03</td><td>12</td><td>11</td><td>14</td><td>14</td><td>15</td></tr><tr><th>4</th><td>2019-05-04</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>2019-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>2019-05-06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>2019-05-07</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>8</th><td>2019-05-08</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>2019-05-09</td><td>45</td><td>26</td><td>55</td><td>43</td><td>32</td></tr><tr><th>10</th><td>2019-05-10</td><td>66</td><td>48</td><td>50</td><td>48</td><td>50</td></tr><tr><th>11</th><td>2019-05-11</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>12</th><td>2019-05-12</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>13</th><td>2019-05-13</td><td>18</td><td>14</td><td>0</td><td>9</td><td>5</td></tr><tr><th>14</th><td>2019-05-14</td><td>22</td><td>21</td><td>25</td><td>18</td><td>15</td></tr><tr><th>15</th><td>2019-05-15</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>16</th><td>2019-05-16</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>17</th><td>2019-05-17</td><td>3</td><td>5</td><td>0</td><td>3</td><td>5</td></tr><tr><th>18</th><td>2019-05-18</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>19</th><td>2019-05-19</td><td>23</td><td>32</td><td>16</td><td>27</td><td>25</td></tr><tr><th>20</th><td>2019-05-20</td><td>40</td><td>5</td><td>27</td><td>51</td><td>38</td></tr><tr><th>21</th><td>2019-05-21</td><td>0</td><td>0</td><td>3</td><td>2</td><td>0</td></tr><tr><th>22</th><td>2019-05-22</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>23</th><td>2019-05-23</td><td>63</td><td>44</td><td>186</td><td>66</td><td>99</td></tr><tr><th>24</th><td>2019-05-24</td><td>9</td><td>3</td><td>12</td><td>6</td><td>12</td></tr><tr><th>25</th><td>2019-05-25</td><td>0</td><td>1</td><td>7</td><td>2</td><td>2</td></tr><tr><th>26</th><td>2019-05-26</td><td>3</td><td>2</td><td>21</td><td>3</td><td>5</td></tr><tr><th>27</th><td>2019-05-27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>28</th><td>2019-05-28</td><td>3</td><td>4</td><td>0</td><td>8</td><td>8</td></tr><tr><th>29</th><td>2019-05-29</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td></tr><tr><th>30</th><td>2019-05-30</td><td>7</td><td>6</td><td>10</td><td>12</td><td>10</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 24 & 24 & 15 & 21 & 22 \\\\\n",
       "\t2 & 2019-05-02 & 12 & 7 & 7 & 8 & 10 \\\\\n",
       "\t3 & 2019-05-03 & 12 & 11 & 14 & 14 & 15 \\\\\n",
       "\t4 & 2019-05-04 & 2 & 0 & 0 & 2 & 0 \\\\\n",
       "\t5 & 2019-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 2019-05-06 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 2019-05-07 & 3 & 0 & 0 & 0 & 0 \\\\\n",
       "\t8 & 2019-05-08 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t9 & 2019-05-09 & 45 & 26 & 55 & 43 & 32 \\\\\n",
       "\t10 & 2019-05-10 & 66 & 48 & 50 & 48 & 50 \\\\\n",
       "\t11 & 2019-05-11 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t12 & 2019-05-12 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t13 & 2019-05-13 & 18 & 14 & 0 & 9 & 5 \\\\\n",
       "\t14 & 2019-05-14 & 22 & 21 & 25 & 18 & 15 \\\\\n",
       "\t15 & 2019-05-15 & 2 & 0 & 0 & 0 & 0 \\\\\n",
       "\t16 & 2019-05-16 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t17 & 2019-05-17 & 3 & 5 & 0 & 3 & 5 \\\\\n",
       "\t18 & 2019-05-18 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t19 & 2019-05-19 & 23 & 32 & 16 & 27 & 25 \\\\\n",
       "\t20 & 2019-05-20 & 40 & 5 & 27 & 51 & 38 \\\\\n",
       "\t21 & 2019-05-21 & 0 & 0 & 3 & 2 & 0 \\\\\n",
       "\t22 & 2019-05-22 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t23 & 2019-05-23 & 63 & 44 & 186 & 66 & 99 \\\\\n",
       "\t24 & 2019-05-24 & 9 & 3 & 12 & 6 & 12 \\\\\n",
       "\t25 & 2019-05-25 & 0 & 1 & 7 & 2 & 2 \\\\\n",
       "\t26 & 2019-05-26 & 3 & 2 & 21 & 3 & 5 \\\\\n",
       "\t27 & 2019-05-27 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t28 & 2019-05-28 & 3 & 4 & 0 & 8 & 8 \\\\\n",
       "\t29 & 2019-05-29 & 0 & 1 & 0 & 2 & 0 \\\\\n",
       "\t30 & 2019-05-30 & 7 & 6 & 10 & 12 & 10 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "183×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-05-01 │ 24       │ 24       │ 15         │ 21      │ 22       │\n",
       "│ 2   │ 2019-05-02 │ 12       │ 7        │ 7          │ 8       │ 10       │\n",
       "│ 3   │ 2019-05-03 │ 12       │ 11       │ 14         │ 14      │ 15       │\n",
       "│ 4   │ 2019-05-04 │ 2        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 5   │ 2019-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 6   │ 2019-05-06 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 7   │ 2019-05-07 │ 3        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 8   │ 2019-05-08 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 9   │ 2019-05-09 │ 45       │ 26       │ 55         │ 43      │ 32       │\n",
       "│ 10  │ 2019-05-10 │ 66       │ 48       │ 50         │ 48      │ 50       │\n",
       "⋮\n",
       "│ 173 │ 2019-10-20 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 174 │ 2019-10-21 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 175 │ 2019-10-22 │ 31       │ 37       │ 37         │ 53      │ 28       │\n",
       "│ 176 │ 2019-10-23 │ 58       │ 49       │ 49         │ 28      │ 65       │\n",
       "│ 177 │ 2019-10-24 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 178 │ 2019-10-25 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 179 │ 2019-10-26 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 180 │ 2019-10-27 │ 102      │ 94       │ 94         │ 98      │ 83       │\n",
       "│ 181 │ 2019-10-28 │ 3        │ 2        │ 2          │ 2       │ 2        │\n",
       "│ 182 │ 2019-10-29 │ 0        │ 1        │ 1          │ 0       │ 2        │\n",
       "│ 183 │ 2019-10-30 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation_daily_max_train = filter(row -> Year(row[:date]) != Year(2019), precipitation_daily_max)\n",
    "precipitation_daily_max_pred  = filter(row -> Year(row[:date]) == Year(2019), precipitation_daily_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envoyer vers fichier CSV\n",
    "Valider que les dates correspondent pour x et y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>date</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>161,098 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr><tr><th>6</th><td>0642-01D</td><td>2013-05-06</td><td>0</td></tr><tr><th>7</th><td>0642-01D</td><td>2013-05-07</td><td>0</td></tr><tr><th>8</th><td>0642-01D</td><td>2013-05-08</td><td>0</td></tr><tr><th>9</th><td>0642-01D</td><td>2013-05-09</td><td>0</td></tr><tr><th>10</th><td>0642-01D</td><td>2013-05-10</td><td>0</td></tr><tr><th>11</th><td>0642-01D</td><td>2013-05-11</td><td>0</td></tr><tr><th>12</th><td>0642-01D</td><td>2013-05-12</td><td>0</td></tr><tr><th>13</th><td>0642-01D</td><td>2013-05-13</td><td>0</td></tr><tr><th>14</th><td>0642-01D</td><td>2013-05-14</td><td>0</td></tr><tr><th>15</th><td>0642-01D</td><td>2013-05-15</td><td>0</td></tr><tr><th>16</th><td>0642-01D</td><td>2013-05-16</td><td>0</td></tr><tr><th>17</th><td>0642-01D</td><td>2013-05-17</td><td>0</td></tr><tr><th>18</th><td>0642-01D</td><td>2013-05-18</td><td>0</td></tr><tr><th>19</th><td>0642-01D</td><td>2013-05-19</td><td>0</td></tr><tr><th>20</th><td>0642-01D</td><td>2013-05-20</td><td>0</td></tr><tr><th>21</th><td>0642-01D</td><td>2013-05-21</td><td>0</td></tr><tr><th>22</th><td>0642-01D</td><td>2013-05-22</td><td>0</td></tr><tr><th>23</th><td>0642-01D</td><td>2013-05-23</td><td>0</td></tr><tr><th>24</th><td>0642-01D</td><td>2013-05-24</td><td>0</td></tr><tr><th>25</th><td>0642-01D</td><td>2013-05-25</td><td>0</td></tr><tr><th>26</th><td>0642-01D</td><td>2013-05-26</td><td>0</td></tr><tr><th>27</th><td>0642-01D</td><td>2013-05-27</td><td>0</td></tr><tr><th>28</th><td>0642-01D</td><td>2013-05-28</td><td>0</td></tr><tr><th>29</th><td>0642-01D</td><td>2013-05-29</td><td>0</td></tr><tr><th>30</th><td>0642-01D</td><td>2013-05-30</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & date & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\t6 & 0642-01D & 2013-05-06 & 0 \\\\\n",
       "\t7 & 0642-01D & 2013-05-07 & 0 \\\\\n",
       "\t8 & 0642-01D & 2013-05-08 & 0 \\\\\n",
       "\t9 & 0642-01D & 2013-05-09 & 0 \\\\\n",
       "\t10 & 0642-01D & 2013-05-10 & 0 \\\\\n",
       "\t11 & 0642-01D & 2013-05-11 & 0 \\\\\n",
       "\t12 & 0642-01D & 2013-05-12 & 0 \\\\\n",
       "\t13 & 0642-01D & 2013-05-13 & 0 \\\\\n",
       "\t14 & 0642-01D & 2013-05-14 & 0 \\\\\n",
       "\t15 & 0642-01D & 2013-05-15 & 0 \\\\\n",
       "\t16 & 0642-01D & 2013-05-16 & 0 \\\\\n",
       "\t17 & 0642-01D & 2013-05-17 & 0 \\\\\n",
       "\t18 & 0642-01D & 2013-05-18 & 0 \\\\\n",
       "\t19 & 0642-01D & 2013-05-19 & 0 \\\\\n",
       "\t20 & 0642-01D & 2013-05-20 & 0 \\\\\n",
       "\t21 & 0642-01D & 2013-05-21 & 0 \\\\\n",
       "\t22 & 0642-01D & 2013-05-22 & 0 \\\\\n",
       "\t23 & 0642-01D & 2013-05-23 & 0 \\\\\n",
       "\t24 & 0642-01D & 2013-05-24 & 0 \\\\\n",
       "\t25 & 0642-01D & 2013-05-25 & 0 \\\\\n",
       "\t26 & 0642-01D & 2013-05-26 & 0 \\\\\n",
       "\t27 & 0642-01D & 2013-05-27 & 0 \\\\\n",
       "\t28 & 0642-01D & 2013-05-28 & 0 \\\\\n",
       "\t29 & 0642-01D & 2013-05-29 & 0 \\\\\n",
       "\t30 & 0642-01D & 2013-05-30 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "161098×3 DataFrame\n",
       "│ Row    │ NO_OUVRAGE │ date       │ SURVERSE │\n",
       "│        │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├────────┼────────────┼────────────┼──────────┤\n",
       "│ 1      │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2      │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3      │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4      │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5      │ 0642-01D   │ 2013-05-05 │ 0        │\n",
       "│ 6      │ 0642-01D   │ 2013-05-06 │ 0        │\n",
       "│ 7      │ 0642-01D   │ 2013-05-07 │ 0        │\n",
       "│ 8      │ 0642-01D   │ 2013-05-08 │ 0        │\n",
       "│ 9      │ 0642-01D   │ 2013-05-09 │ 0        │\n",
       "│ 10     │ 0642-01D   │ 2013-05-10 │ 0        │\n",
       "⋮\n",
       "│ 161088 │ 4795-01D   │ 2018-10-21 │ 0        │\n",
       "│ 161089 │ 4795-01D   │ 2018-10-22 │ 0        │\n",
       "│ 161090 │ 4795-01D   │ 2018-10-23 │ 0        │\n",
       "│ 161091 │ 4795-01D   │ 2018-10-24 │ 0        │\n",
       "│ 161092 │ 4795-01D   │ 2018-10-25 │ 0        │\n",
       "│ 161093 │ 4795-01D   │ 2018-10-26 │ 0        │\n",
       "│ 161094 │ 4795-01D   │ 2018-10-27 │ 0        │\n",
       "│ 161095 │ 4795-01D   │ 2018-10-28 │ 0        │\n",
       "│ 161096 │ 4795-01D   │ 2018-10-29 │ 0        │\n",
       "│ 161097 │ 4795-01D   │ 2018-10-30 │ 0        │\n",
       "│ 161098 │ 4795-01D   │ 2018-10-31 │ 0        │"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter!(row -> row.date in surverse_df[!, :date], precipitation_daily_max_train)\n",
    "filter!(row -> row.date in precipitation_daily_max_train[!, :date], surverse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/new_datasets/precipitation_daily_max/x_pred.csv\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/new_datasets/precipitation_daily_max/x_train.csv\", precipitation_daily_max_train)\n",
    "CSV.write(\"./data/new_datasets/precipitation_daily_max/x_pred.csv\", precipitation_daily_max_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/new_datasets/surverse_list.csv\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/new_datasets/surverse_list.csv\", surverse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : somme plus importante de précipitations par plages horaires sur une journée \n",
    "- Nous avons extrait cette varibale explicative avec l'idéé en tête que quelsques heures consécutives avec beaucoup de précipitations pourraient causer des surverses plus que des précipitations modérées réparties sur une journée complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th><th>heure</th><th>date</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Date</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-01</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2013-05-01</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2013-05-01</td></tr><tr><th>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2013-05-01</td></tr><tr><th>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>2013-05-01</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& McTavish & Bellevue & Assomption & Trudeau & StHubert & heure & date\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 0 & 2013-05-01 \\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 1 & 2013-05-01 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 2 & 2013-05-01 \\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 3 & 2013-05-01 \\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 4 & 2013-05-01 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │ heure │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼──────────┼──────────┼────────────┼─────────┼──────────┼───────┤\n",
       "│ 1   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0     │\n",
       "│ 2   │ 0        │ 0        │ 0          │ 0       │ 0        │ 1     │\n",
       "│ 3   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2     │\n",
       "│ 4   │ 0        │ 0        │ 0          │ 0       │ 0        │ 3     │\n",
       "│ 5   │ 0        │ 0        │ 0          │ 0       │ 0        │ 4     │"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filledPrec  = CSV.read(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\", missingstring=\"-99999\")\n",
    "first(filledPrec,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions pour séparer les journées en plages horaires de taille \"window\" et effectuer la somme des précipiations sur chaque plage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayPrecipitationSplit (generic function with 1 method)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dayPrecipitationSplit(window,precipitations)\n",
    "    n = size(precipitations,1)\n",
    "    newDf = DataFrame(McTavish = Int64[], Bellevue = Int64[], Assomption = Int64[], Trudeau  = Int64[],\n",
    "                        StHubert = Int64[], heureDebut = Int64[], heureFin = Int64[], date = Date[])\n",
    "\n",
    "    hourgroups = 24/window\n",
    "    for day in groupby(filledPrec, :date)\n",
    "        start = 1\n",
    "        finish = window\n",
    "        date = day[1,:date]\n",
    "        if(size(day, 1)==24)\n",
    "            for i=1:hourgroups\n",
    "                mcTavish, Bellevue, Assomption, Trudeau, StHubert, heureDebut, heureFin = 0,0,0,0,0,0,0\n",
    "                for j=start:finish\n",
    "                    mcTavish += day[j,:McTavish]\n",
    "                    Assomption += day[j,:Assomption]\n",
    "                    Bellevue += day[j,:Bellevue]\n",
    "                    Trudeau += day[j,:Trudeau]\n",
    "                    StHubert += day[j,:StHubert]\n",
    "                    if j == start\n",
    "                        heureDebut = day[j,:heure]\n",
    "                    elseif j == finish\n",
    "                        heureFin = day[j,:heure]\n",
    "                    end\n",
    "                end\n",
    "                start += window\n",
    "                finish += window\n",
    "                push!(newDf,[mcTavish,Bellevue,Assomption,Trudeau,StHubert,heureDebut,heureFin,date])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return newDf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Générations des sommes de plages horaires pour des divisions de journées de 2,3,4,6,8 et 12 heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th><th>heureDebut</th><th>heureFin</th><th>date</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Date</th></tr></thead><tbody><p>5 rows × 8 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>11</td><td>2013-05-01</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>12</td><td>23</td><td>2013-05-01</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>11</td><td>2013-05-02</td></tr><tr><th>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>12</td><td>23</td><td>2013-05-02</td></tr><tr><th>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>11</td><td>2013-05-03</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& McTavish & Bellevue & Assomption & Trudeau & StHubert & heureDebut & heureFin & date\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 2013-05-01 \\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 12 & 23 & 2013-05-01 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 2013-05-02 \\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 12 & 23 & 2013-05-02 \\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 2013-05-03 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │ heureDebut │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │\n",
       "├─────┼──────────┼──────────┼────────────┼─────────┼──────────┼────────────┤\n",
       "│ 1   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0          │\n",
       "│ 2   │ 0        │ 0        │ 0          │ 0       │ 0        │ 12         │\n",
       "│ 3   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0          │\n",
       "│ 4   │ 0        │ 0        │ 0          │ 0       │ 0        │ 12         │\n",
       "│ 5   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0          │"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourSplit2 = dayPrecipitationSplit(2,filledPrec)\n",
    "hourSplit3 = dayPrecipitationSplit(3,filledPrec)\n",
    "hourSplit4 = dayPrecipitationSplit(4,filledPrec)\n",
    "hourSplit6 = dayPrecipitationSplit(6,filledPrec)\n",
    "hourSplit8 = dayPrecipitationSplit(8,filledPrec)\n",
    "hourSplit12 = dayPrecipitationSplit(12,filledPrec)\n",
    "first(hourSplit12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour extraire la plage horaire avec la somme des précipitations la plus grande pour chaque jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxPrecByDay (generic function with 1 method)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function maxPrecByDay(Prec)\n",
    "    n = size(Prec,1)\n",
    "    newDf = DataFrame(McTavish = Int64[], Bellevue = Int64[], Assomption = Int64[], Trudeau  = Int64[],\n",
    "                        StHubert = Int64[], date = Date[])\n",
    "\n",
    "    for day in groupby(Prec, :date)\n",
    "        mcTavish = maximum(day[:,:McTavish])\n",
    "        Assomption = maximum(day[:,:Assomption])\n",
    "        Bellevue = maximum(day[:,:Bellevue])\n",
    "        Trudeau = maximum(day[:,:Trudeau])\n",
    "        StHubert = maximum(day[:,:StHubert])\n",
    "        date = day[1,:date]\n",
    "        push!(newDf,[mcTavish,Bellevue,Assomption,Trudeau,StHubert,date])\n",
    "    end\n",
    "    return newDf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets contenant la nouvelle variables explicative pour les 5 stations pour les journées divisée par sections de 2,3,4,6,8 et 12 heures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th><th>date</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Date</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-01</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-02</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-03</td></tr><tr><th>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-04</td></tr><tr><th>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-05</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& McTavish & Bellevue & Assomption & Trudeau & StHubert & date\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 2013-05-01 \\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 2013-05-02 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 2013-05-03 \\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 2013-05-04 \\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 2013-05-05 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │ date       │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼──────────┼──────────┼────────────┼─────────┼──────────┼────────────┤\n",
       "│ 1   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2013-05-01 │\n",
       "│ 2   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2013-05-02 │\n",
       "│ 3   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2013-05-03 │\n",
       "│ 4   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2013-05-04 │\n",
       "│ 5   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2013-05-05 │"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSum2hours = maxPrecByDay(hourSplit2)\n",
    "maxSum3hours = maxPrecByDay(hourSplit3)\n",
    "maxSum4hours = maxPrecByDay(hourSplit4)\n",
    "maxSum6hours = maxPrecByDay(hourSplit6)\n",
    "maxSum8hours = maxPrecByDay(hourSplit8)\n",
    "maxSum12hours = maxPrecByDay(hourSplit12)\n",
    "first(maxSum12hours,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Écriture des dataframes ver des fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/new_datasets/max_precipitation_day_split/maxPrecBy12hours.csv\""
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy2hours.csv\",maxSum2hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy3hours.csv\",maxSum3hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy4hours.csv\",maxSum4hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy6hours.csv\",maxSum6hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy8hours.csv\",maxSum8hours)\n",
    "CSV.write(\"./data/new_datasets/max_precipitation_day_split/maxPrecBy12hours.csv\",maxSum12hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelle variable explicative : Somme de la journee + les deux dernieres heures du jour précédent\n",
    "- Nous avons décidé d'ajouter les deux heures de la journée précedente, car nous croyons que les dernières heures de cette journée peuvent effet impoartant sur la journée qui suit et pas sur celle dont elles font parite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th><th>heure</th><th>date</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Date</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2013-05-01</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2013-05-01</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2013-05-01</td></tr><tr><th>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2013-05-01</td></tr><tr><th>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>2013-05-01</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& McTavish & Bellevue & Assomption & Trudeau & StHubert & heure & date\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 0 & 2013-05-01 \\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 1 & 2013-05-01 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 2 & 2013-05-01 \\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 3 & 2013-05-01 \\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 4 & 2013-05-01 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │ heure │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼──────────┼──────────┼────────────┼─────────┼──────────┼───────┤\n",
       "│ 1   │ 0        │ 0        │ 0          │ 0       │ 0        │ 0     │\n",
       "│ 2   │ 0        │ 0        │ 0          │ 0       │ 0        │ 1     │\n",
       "│ 3   │ 0        │ 0        │ 0          │ 0       │ 0        │ 2     │\n",
       "│ 4   │ 0        │ 0        │ 0          │ 0       │ 0        │ 3     │\n",
       "│ 5   │ 0        │ 0        │ 0          │ 0       │ 0        │ 4     │"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filledPrec  = CSV.read(\"data/new_datasets/precipitation_filed_mean_per_hour.csv\", missingstring=\"-99999\")\n",
    "first(filledPrec,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Somme et ajout des 2 dernières heures de la journée précédente pour les précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2013-05-01</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2013-05-02</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2013-05-03</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>2013-05-04</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2013-05-05</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-05-01 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2013-05-02 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2013-05-03 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t4 & 2013-05-04 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2013-05-05 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2013-05-01 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 2   │ 2013-05-02 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 3   │ 2013-05-03 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 4   │ 2013-05-04 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 5   │ 2013-05-05 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1:size(precipitation_daily_sum, 1)\n",
    "    ind = findfirst(filledPrec[:,:date] .== precipitation_daily_sum[i,:date])\n",
    "    for h=1:2\n",
    "        for key in names(precipitation_daily_sum[:, Not(:date)])\n",
    "            if ind-h > 0\n",
    "                precipitation_daily_sum[i, key] += filledPrec[ind-h, key]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "first(precipitation_daily_sum, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportation vers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/new_datasets/sum_day_last_2.csv\""
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/new_datasets/sum_day_last_2.csv\",precipitation_daily_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset avec toutes les surverses des autres ouvrages ayant assez de données par date\n",
    "- Nous n'avons finalement pas utilisé ces données, car il y avait une quatité très importante de données manquantes et nous n'avions pas accès aux données pour 2019 afin d'effectuer les préditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/new_datasets/surversesVoisines\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surversesVoisines = DataFrame()\n",
    "surversesVoisines[:,:date] = maxSum2hours[:,:date]\n",
    "ouvrages = groupby(surverse_df, :NO_OUVRAGE)\n",
    "for subdf in ouvrages\n",
    "            length = (size(subdf, 1))\n",
    "            if (length > 1000)\n",
    "                subdf = rename(subdf,:SURVERSE => subdf[1,:NO_OUVRAGE])\n",
    "                dateAndSurverse = subdf[:,Not(:NO_OUVRAGE)]\n",
    "                surversesVoisines = join(surversesVoisines, dateAndSurverse, on = :date, kind = :left)    \n",
    "            end\n",
    "       end\n",
    "first(surversesVoisines,5)\n",
    "CSV.write(\"./data/new_datasets/surversesVoisines\",surversesVoisines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
